{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_ai/blob/master/section_5/train_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wnqByPA6jQit"
   },
   "source": [
    "# 出力層の学習\n",
    "出力層のパラメータを更新する仕組みをニューラルネットワークに導入し、実際にパラメータが更新されることを確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONf3juW4Q8PA"
   },
   "source": [
    "## ● ニューラルネットワークの復習\n",
    "前回構築したニューラルネットワークを復習します。  \n",
    "以下のコードで実装されるニューラルネットワークは、中間層に2つ、出力層に2つのニューロンを持ちます。  \n",
    "SetosaとVersicolorにIrisの品種を分類しますが、パラメータが調整されていないため、まだ適切に品種を分類することができません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrAGPSufjKix"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "sl_data = iris_data[:100, 0] # SetosaとVersicolor、Sepal length\n",
    "sw_data = iris_data[:100, 1] # SetosaとVersicolor、Sepal width\n",
    "\n",
    "# 平均値を0に\n",
    "sl_ave = np.average(sl_data)  # 平均値\n",
    "sl_data -= sl_ave  # 平均値を引く\n",
    "sw_ave = np.average(sw_data)\n",
    "sw_data -= sw_ave\n",
    "\n",
    "# 入力をリストに格納\n",
    "input_data = []\n",
    "for i in range(100):  # iには0から99までが入る\n",
    "    input_data.append([sl_data[i], sw_data[i]])\n",
    "\n",
    "# シグモイド関数\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# ニューロン\n",
    "class Neuron:\n",
    "    def __init__(self):  # 初期設定\n",
    "        self.input_sum = 0.0\n",
    "        self.output = 0.0\n",
    "\n",
    "    def set_input(self, inp):\n",
    "        self.input_sum += inp\n",
    "\n",
    "    def get_output(self):\n",
    "        self.output = sigmoid(self.input_sum)\n",
    "        return self.output\n",
    "\n",
    "    def reset(self):\n",
    "        self.input_sum = 0\n",
    "        self.output = 0\n",
    "\n",
    "# ニューラルネットワーク\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):  # 初期設定\n",
    "        # 重み\n",
    "        self.w_im = [[4.0, 4.0], [4.0, 4.0]]  # 入力:2 ニューロン数:2\n",
    "        self.w_mo = [[1.531288543605751, -0.6352400552991943]]  # 入力:2 ニューロン数:1\n",
    "\n",
    "        # バイアス\n",
    "        self.b_m = [2.0, -2.0]  # ニューロン数:2\n",
    "        self.b_o = [0.09558734488370531]  # ニューロン数:1\n",
    "\n",
    "        # 各層の宣言\n",
    "        self.input_layer = [0.0, 0.0]\n",
    "        self.middle_layer = [Neuron(), Neuron()]\n",
    "        self.output_layer = [Neuron()]\n",
    "\n",
    "    def commit(self, input_data):  # 実行\n",
    "        # 各層のリセット\n",
    "        self.input_layer[0] = input_data[0]  # 入力層は値を受け取るのみ\n",
    "        self.input_layer[1] = input_data[1]\n",
    "        self.middle_layer[0].reset()\n",
    "        self.middle_layer[1].reset()\n",
    "        self.output_layer[0].reset()\n",
    "\n",
    "        # 入力層→中間層\n",
    "        self.middle_layer[0].set_input(self.input_layer[0] * self.w_im[0][0])\n",
    "        self.middle_layer[0].set_input(self.input_layer[1] * self.w_im[0][1])\n",
    "        self.middle_layer[0].set_input(self.b_m[0])\n",
    "\n",
    "        self.middle_layer[1].set_input(self.input_layer[0] * self.w_im[1][0])\n",
    "        self.middle_layer[1].set_input(self.input_layer[1] * self.w_im[1][1])\n",
    "        self.middle_layer[1].set_input(self.b_m[1])\n",
    "\n",
    "        # 中間層→出力層\n",
    "        self.output_layer[0].set_input(self.middle_layer[0].get_output() * self.w_mo[0][0])\n",
    "        self.output_layer[0].set_input(self.middle_layer[1].get_output() * self.w_mo[0][1])\n",
    "        self.output_layer[0].set_input(self.b_o[0])\n",
    "\n",
    "        return self.output_layer[0].get_output()\n",
    "\n",
    "# ニューラルネットワークのインスタンス\n",
    "neural_network = NeuralNetwork()\n",
    "\n",
    "# 実行\n",
    "st_predicted = [[], []]  # Setosa\n",
    "vc_predicted = [[], []]  # Versicolor\n",
    "for data in input_data:\n",
    "    if neural_network.commit(data) < 0.5:\n",
    "        st_predicted[0].append(data[0]+sl_ave)\n",
    "        st_predicted[1].append(data[1]+sw_ave)\n",
    "    else:\n",
    "        vc_predicted[0].append(data[0]+sl_ave)\n",
    "        vc_predicted[1].append(data[1]+sw_ave)\n",
    "\n",
    "# 分類結果をグラフ表示\n",
    "plt.scatter(st_predicted[0], st_predicted[1], label=\"Setosa\")\n",
    "plt.scatter(vc_predicted[0], vc_predicted[1], label=\"Versicolor\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Sepal length (cm)\")\n",
    "plt.ylabel(\"Sepal width (cm)\")\n",
    "plt.title(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uuSI_VxrSLNm"
   },
   "source": [
    "## ● 出力層のパラメータを更新\n",
    "出力層の重みとバイアスを更新します。  \n",
    "\n",
    "最初に、修正量のベース$\\delta_o$を求めます。   \n",
    "**$\\delta_o$ = (出力 - 正解) × 活性化関数の微分形**  \n",
    "  \n",
    "活性化関数がシグモイド関数の場合、上記は以下の形になります。  \n",
    "**$\\delta_o$ = (出力 - 正解) × 出力 × (1 - 出力)**  \n",
    "  \n",
    "そして、この$\\delta_o$を使って出力層における重みとバイアスの修正量を求めます。  \n",
    "**重みの修正量 = - 学習係数 × $\\delta_o$ × 入力**  \n",
    "**バイアスの修正量 = - 学習係数 × $\\delta_o$**  \n",
    "以下のコードは、これらのこれらの式を使って出力層の各パラメータを1回だけ更新します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQOo_wKoNGvm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37100000000000133, 0.40100000000000025, 0], [-0.5710000000000006, -0.09899999999999975, 0], [-0.7710000000000008, 0.10100000000000042, 0], [-0.8710000000000013, 0.001000000000000334, 0], [-0.471000000000001, 0.5010000000000003, 0], [-0.07100000000000062, 0.8010000000000002, 0], [-0.8710000000000013, 0.30100000000000016, 0], [-0.471000000000001, 0.30100000000000016, 0], [-1.0710000000000006, -0.19899999999999984, 0], [-0.5710000000000006, 0.001000000000000334, 0], [-0.07100000000000062, 0.6010000000000004, 0], [-0.6710000000000012, 0.30100000000000016, 0], [-0.6710000000000012, -0.09899999999999975, 0], [-1.1710000000000012, -0.09899999999999975, 0], [0.32899999999999885, 0.9010000000000002, 0], [0.2289999999999992, 1.3010000000000006, 0], [-0.07100000000000062, 0.8010000000000002, 0], [-0.37100000000000133, 0.40100000000000025, 0], [0.2289999999999992, 0.7010000000000001, 0], [-0.37100000000000133, 0.7010000000000001, 0], [-0.07100000000000062, 0.30100000000000016, 0], [-0.37100000000000133, 0.6010000000000004, 0], [-0.8710000000000013, 0.5010000000000003, 0], [-0.37100000000000133, 0.20100000000000007, 0], [-0.6710000000000012, 0.30100000000000016, 0], [-0.471000000000001, -0.09899999999999975, 0], [-0.471000000000001, 0.30100000000000016, 0], [-0.2710000000000008, 0.40100000000000025, 0], [-0.2710000000000008, 0.30100000000000016, 0], [-0.7710000000000008, 0.10100000000000042, 0], [-0.6710000000000012, 0.001000000000000334, 0], [-0.07100000000000062, 0.30100000000000016, 0], [-0.2710000000000008, 1.001, 0], [0.028999999999999027, 1.1010000000000004, 0], [-0.5710000000000006, 0.001000000000000334, 0], [-0.471000000000001, 0.10100000000000042, 0], [0.028999999999999027, 0.40100000000000025, 0], [-0.5710000000000006, 0.5010000000000003, 0], [-1.0710000000000006, -0.09899999999999975, 0], [-0.37100000000000133, 0.30100000000000016, 0], [-0.471000000000001, 0.40100000000000025, 0], [-0.971000000000001, -0.7989999999999999, 0], [-1.0710000000000006, 0.10100000000000042, 0], [-0.471000000000001, 0.40100000000000025, 0], [-0.37100000000000133, 0.7010000000000001, 0], [-0.6710000000000012, -0.09899999999999975, 0], [-0.37100000000000133, 0.7010000000000001, 0], [-0.8710000000000013, 0.10100000000000042, 0], [-0.17100000000000115, 0.6010000000000004, 0], [-0.471000000000001, 0.20100000000000007, 0], [1.528999999999999, 0.10100000000000042, 1], [0.9289999999999994, 0.10100000000000042, 1], [1.4289999999999994, 0.001000000000000334, 1], [0.028999999999999027, -0.7989999999999999, 1], [1.028999999999999, -0.29899999999999993, 1], [0.2289999999999992, -0.29899999999999993, 1], [0.8289999999999988, 0.20100000000000007, 1], [-0.5710000000000006, -0.6989999999999998, 1], [1.1289999999999987, -0.19899999999999984, 1], [-0.2710000000000008, -0.3989999999999996, 1], [-0.471000000000001, -1.0989999999999998, 1], [0.4289999999999994, -0.09899999999999975, 1], [0.528999999999999, -0.8989999999999996, 1], [0.6289999999999987, -0.19899999999999984, 1], [0.12899999999999867, -0.19899999999999984, 1], [1.2289999999999992, 0.001000000000000334, 1], [0.12899999999999867, -0.09899999999999975, 1], [0.32899999999999885, -0.3989999999999996, 1], [0.7289999999999992, -0.8989999999999996, 1], [0.12899999999999867, -0.5989999999999998, 1], [0.4289999999999994, 0.10100000000000042, 1], [0.6289999999999987, -0.29899999999999993, 1], [0.8289999999999988, -0.5989999999999998, 1], [0.6289999999999987, -0.29899999999999993, 1], [0.9289999999999994, -0.19899999999999984, 1], [1.1289999999999987, -0.09899999999999975, 1], [1.3289999999999988, -0.29899999999999993, 1], [1.2289999999999992, -0.09899999999999975, 1], [0.528999999999999, -0.19899999999999984, 1], [0.2289999999999992, -0.49899999999999967, 1], [0.028999999999999027, -0.6989999999999998, 1], [0.028999999999999027, -0.6989999999999998, 1], [0.32899999999999885, -0.3989999999999996, 1], [0.528999999999999, -0.3989999999999996, 1], [-0.07100000000000062, -0.09899999999999975, 1], [0.528999999999999, 0.30100000000000016, 1], [1.2289999999999992, 0.001000000000000334, 1], [0.8289999999999988, -0.7989999999999999, 1], [0.12899999999999867, -0.09899999999999975, 1], [0.028999999999999027, -0.5989999999999998, 1], [0.028999999999999027, -0.49899999999999967, 1], [0.6289999999999987, -0.09899999999999975, 1], [0.32899999999999885, -0.49899999999999967, 1], [-0.471000000000001, -0.7989999999999999, 1], [0.12899999999999867, -0.3989999999999996, 1], [0.2289999999999992, -0.09899999999999975, 1], [0.2289999999999992, -0.19899999999999984, 1], [0.7289999999999992, -0.19899999999999984, 1], [-0.37100000000000133, -0.5989999999999998, 1], [0.2289999999999992, -0.29899999999999993, 1]]\n",
      "-------- Before train --------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.0, -1.0]]\n",
      "[2.0, -2.0]\n",
      "[-0.5]\n",
      "-------- After train (0)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.9628174102667754, -1.0055134242038597]]\n",
      "[2.0, -2.0]\n",
      "[-0.541645676531177]\n",
      "-------- After train (1)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.951776539663377, -1.0058152921575685]]\n",
      "[2.0, -2.0]\n",
      "[-0.5744798757630611]\n",
      "-------- After train (2)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.9410079265532835, -1.0061097163312225]]\n",
      "[2.0, -2.0]\n",
      "[-0.6065044144981735]\n",
      "-------- After train (3)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.9357990613646888, -1.0062263512120875]]\n",
      "[2.0, -2.0]\n",
      "[-0.6345955415194932]\n",
      "-------- After train (4)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.9012245496183436, -1.0113530503276307]]\n",
      "[2.0, -2.0]\n",
      "[-0.6733200882157406]\n",
      "-------- After train (5)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8748413190419547, -1.030355870058936]]\n",
      "[2.0, -2.0]\n",
      "[-0.6998958934442676]\n",
      "-------- After train (6)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8617722527612119, -1.030770410680117]]\n",
      "[2.0, -2.0]\n",
      "[-0.7302570309404751]\n",
      "-------- After train (7)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8339909631249902, -1.033029149345576]]\n",
      "[2.0, -2.0]\n",
      "[-0.7654596837726697]\n",
      "-------- After train (8)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8330499711793807, -1.033047161154145]]\n",
      "[2.0, -2.0]\n",
      "[-0.786875157122431]\n",
      "-------- After train (9)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8210196515673043, -1.033428753538625]]\n",
      "[2.0, -2.0]\n",
      "[-0.8148231512651937]\n",
      "-------- After train (10)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7960658580615133, -1.0468681944770553]]\n",
      "[2.0, -2.0]\n",
      "[-0.8401823070299709]\n",
      "-------- After train (11)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7775245601802174, -1.0477517786380572]]\n",
      "[2.0, -2.0]\n",
      "[-0.8697467874877335]\n",
      "-------- After train (12)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7718118688221433, -1.0478910762321763]]\n",
      "[2.0, -2.0]\n",
      "[-0.8922815242694773]\n",
      "-------- After train (13)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7709922896921113, -1.0479067640416906]]\n",
      "[2.0, -2.0]\n",
      "[-0.9109338359062699]\n",
      "-------- After train (14)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7575730427001292, -1.0606518760803307]]\n",
      "[2.0, -2.0]\n",
      "[-0.9243663388322101]\n",
      "-------- After train (15)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.745395222516596, -1.0726386009885076]]\n",
      "[2.0, -2.0]\n",
      "[-0.9365477822662696]\n",
      "-------- After train (16)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7289532255349023, -1.0844811349708852]]\n",
      "[2.0, -2.0]\n",
      "[-0.9531097915353152]\n",
      "-------- After train (17)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7040717202622946, -1.0881705577459717]]\n",
      "[2.0, -2.0]\n",
      "[-0.9809778644056103]\n",
      "-------- After train (18)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6917926502766487, -1.0986189467588952]]\n",
      "[2.0, -2.0]\n",
      "[-0.9932972061909587]\n",
      "-------- After train (19)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6703869152974723, -1.1060770922885754]]\n",
      "[2.0, -2.0]\n",
      "[-1.015476819105409]\n",
      "-------- After train (20)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6485948709374307, -1.111899458685863]]\n",
      "[2.0, -2.0]\n",
      "[-1.0384441887716007]\n",
      "-------- After train (21)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6277574422026927, -1.1174667722828138]]\n",
      "[2.0, -2.0]\n",
      "[-1.0604054568718615]\n",
      "-------- After train (22)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6139176962380432, -1.118126304339574]]\n",
      "[2.0, -2.0]\n",
      "[-1.0824732161911828]\n",
      "-------- After train (23)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5959679853252431, -1.119585693252164]]\n",
      "[2.0, -2.0]\n",
      "[-1.1052179285488735]\n",
      "-------- After train (24)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5830186414097804, -1.1202027932659993]]\n",
      "[2.0, -2.0]\n",
      "[-1.1258659235048116]\n",
      "-------- After train (25)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5752625401059346, -1.1204488107689616]]\n",
      "[2.0, -2.0]\n",
      "[-1.143884353671285]\n",
      "-------- After train (26)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5589140943492067, -1.1217780099182602]]\n",
      "[2.0, -2.0]\n",
      "[-1.1646000464219088]\n",
      "-------- After train (27)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.541575485553646, -1.12525174534028]]\n",
      "[2.0, -2.0]\n",
      "[-1.1833337128627444]\n",
      "-------- After train (28)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5247282520320976, -1.1277498485044817]]\n",
      "[2.0, -2.0]\n",
      "[-1.202203147259797]\n",
      "-------- After train (29)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5196210902655921, -1.1278894831879314]]\n",
      "[2.0, -2.0]\n",
      "[-1.2173912219121066]\n",
      "-------- After train (30)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5146181225930377, -1.1280262691052774]]\n",
      "[2.0, -2.0]\n",
      "[-1.2322694360685849]\n",
      "-------- After train (31)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5000989247271186, -1.1319054870608496]]\n",
      "[2.0, -2.0]\n",
      "[-1.2475717078120565]\n",
      "-------- After train (32)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.49268295392170586, -1.1372469237715608]]\n",
      "[2.0, -2.0]\n",
      "[-1.2550418087587338]\n",
      "-------- After train (33)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.4876364054097706, -1.1419245493144121]]\n",
      "[2.0, -2.0]\n",
      "[-1.2600957942132847]\n",
      "-------- After train (34)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.4813314932944982, -1.1421245362246175]]\n",
      "[2.0, -2.0]\n",
      "[-1.2747429235124415]\n",
      "-------- After train (35)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.47146598989253574, -1.1425946760498926]]\n",
      "[2.0, -2.0]\n",
      "[-1.2904736714029406]\n",
      "-------- After train (36)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.4612205839056665, -1.1471117257517183]]\n",
      "[2.0, -2.0]\n",
      "[-1.3009673642290616]\n",
      "-------- After train (37)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.44802577074818223, -1.1485553574574754]]\n",
      "[2.0, -2.0]\n",
      "[-1.3165249217510684]\n",
      "-------- After train (38)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.44732175255467993, -1.1485691188098153]]\n",
      "[2.0, -2.0]\n",
      "[-1.3274971109787994]\n",
      "-------- After train (39)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.43472869620936, -1.149946912886587]]\n",
      "[2.0, -2.0]\n",
      "[-1.3423451574143082]\n",
      "-------- After train (40)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.42252757974574423, -1.1512818252011672]]\n",
      "[2.0, -2.0]\n",
      "[-1.356731080803283]\n",
      "-------- After train (41)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.42246553031831213, -1.1512829686145842]]\n",
      "[2.0, -2.0]\n",
      "[-1.3667690683470253]\n",
      "-------- After train (42)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.4210611086633844, -1.1513125339227366]]\n",
      "[2.0, -2.0]\n",
      "[-1.3773773741460884]\n",
      "-------- After train (43)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.409554103946757, -1.1525715041445161]]\n",
      "[2.0, -2.0]\n",
      "[-1.3909448938713216]\n",
      "-------- After train (44)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.40024945602666484, -1.15581341190232]]\n",
      "[2.0, -2.0]\n",
      "[-1.4005859311621995]\n",
      "-------- After train (45)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.39753151434191053, -1.1558796858726628]]\n",
      "[2.0, -2.0]\n",
      "[-1.4113073401470384]\n",
      "-------- After train (46)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.3886498229817112, -1.1589742279091082]]\n",
      "[2.0, -2.0]\n",
      "[-1.4205101298006744]\n",
      "-------- After train (47)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.38601555357067585, -1.1590384616245706]]\n",
      "[2.0, -2.0]\n",
      "[-1.430901478478383]\n",
      "-------- After train (48)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.3786406513258776, -1.1622899481960693]]\n",
      "[2.0, -2.0]\n",
      "[-1.4384551038670468]\n",
      "-------- After train (49)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.37002219281900117, -1.1628195582326981]]\n",
      "[2.0, -2.0]\n",
      "[-1.4505081821937102]\n",
      "-------- After train (50)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.39374851795692684, -1.1393441256709158]]\n",
      "[2.0, -2.0]\n",
      "[-1.4267771250911332]\n",
      "-------- After train (51)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.4205256201157706, -1.115384114403713]]\n",
      "[2.0, -2.0]\n",
      "[-1.3999411546523752]\n",
      "-------- After train (52)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.447041962146118, -1.0894836732713693]]\n",
      "[2.0, -2.0]\n",
      "[-1.373413043062441]\n",
      "-------- After train (53)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.4572173493846803, -1.0892355578258257]]\n",
      "[2.0, -2.0]\n",
      "[-1.3332744010983113]\n",
      "-------- After train (54)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.4908408788603822, -1.065017831057793]]\n",
      "[2.0, -2.0]\n",
      "[-1.2994054490814353]\n",
      "-------- After train (55)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5275368819210348, -1.061002956965933]]\n",
      "[2.0, -2.0]\n",
      "[-1.2561384341089634]\n",
      "-------- After train (56)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5609997518658183, -1.0310605555756036]]\n",
      "[2.0, -2.0]\n",
      "[-1.2226019975182092]\n",
      "-------- After train (57)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5628025882294074, -1.0310260469449894]]\n",
      "[2.0, -2.0]\n",
      "[-1.1815723221011518]\n",
      "-------- After train (58)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.5993460646159658, -0.9999308208718676]]\n",
      "[2.0, -2.0]\n",
      "[-1.144908993676679]\n",
      "-------- After train (59)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6139695017546573, -0.9995310021253381]]\n",
      "[2.0, -2.0]\n",
      "[-1.1014206796012527]\n",
      "-------- After train (60)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6145462776793967, -0.9995202945863872]]\n",
      "[2.0, -2.0]\n",
      "[-1.0591773570877019]\n",
      "-------- After train (61)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6572724783825333, -0.9846337128789937]]\n",
      "[2.0, -2.0]\n",
      "[-1.0149064832390553]\n",
      "-------- After train (62)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.6851109082458808, -0.9833070745901373]]\n",
      "[2.0, -2.0]\n",
      "[-0.9705175347987206]\n",
      "-------- After train (63)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.728489255938227, -0.9641821953261506]]\n",
      "[2.0, -2.0]\n",
      "[-0.9260879576231988]\n",
      "-------- After train (64)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.7650708039639993, -0.960179843648611]]\n",
      "[2.0, -2.0]\n",
      "[-0.8829558927078122]\n",
      "-------- After train (65)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8078913130007133, -0.919510483769431]]\n",
      "[2.0, -2.0]\n",
      "[-0.8400930842902029]\n",
      "-------- After train (66)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8448426103072402, -0.9140313555431423]]\n",
      "[2.0, -2.0]\n",
      "[-0.7987064625923626]\n",
      "-------- After train (67)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.8790577078257829, -0.9102879149196333]]\n",
      "[2.0, -2.0]\n",
      "[-0.7583645993607583]\n",
      "-------- After train (68)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.9103517302836024, -0.907743575925699]]\n",
      "[2.0, -2.0]\n",
      "[-0.7187108387639429]\n",
      "-------- After train (69)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.9323829287255924, -0.9069024676040888]]\n",
      "[2.0, -2.0]\n",
      "[-0.6771397201783809]\n",
      "-------- After train (70)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[0.9731050101193832, -0.8849706515996486]]\n",
      "[2.0, -2.0]\n",
      "[-0.6357561283452824]\n",
      "-------- After train (71)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.009191059766553, -0.872397618712823]]\n",
      "[2.0, -2.0]\n",
      "[-0.5983654658165504]\n",
      "-------- After train (72)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.0421631474818978, -0.8635881847565369]]\n",
      "[2.0, -2.0]\n",
      "[-0.5636150718327262]\n",
      "-------- After train (73)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.0754211986396578, -0.8520004777327218]]\n",
      "[2.0, -2.0]\n",
      "[-0.5291546479469923]\n",
      "-------- After train (74)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.1139175409320308, -0.8242730525116702]]\n",
      "[2.0, -2.0]\n",
      "[-0.49037731581510446]\n",
      "-------- After train (75)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.1533512996513418, -0.7889879310068104]]\n",
      "[2.0, -2.0]\n",
      "[-0.45085686371379174]\n",
      "-------- After train (76)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.1908524648804777, -0.7554320840711268]]\n",
      "[2.0, -2.0]\n",
      "[-0.4132732538243369]\n",
      "-------- After train (77)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.2268100672829618, -0.7221031268521946]]\n",
      "[2.0, -2.0]\n",
      "[-0.3772626618141974]\n",
      "-------- After train (78)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.251077984505945, -0.7136477452207152]]\n",
      "[2.0, -2.0]\n",
      "[-0.3521173906628305]\n",
      "-------- After train (79)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.2699271322703298, -0.7124894524900658]]\n",
      "[2.0, -2.0]\n",
      "[-0.3257564986061226]\n",
      "-------- After train (80)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.2819132695129718, -0.7121617400430785]]\n",
      "[2.0, -2.0]\n",
      "[-0.2901111919647714]\n",
      "-------- After train (81)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.2936240051089545, -0.7118415573403036]]\n",
      "[2.0, -2.0]\n",
      "[-0.25528489614783995]\n",
      "-------- After train (82)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.3109366858797527, -0.7099473937341901]]\n",
      "[2.0, -2.0]\n",
      "[-0.23487210032139366]\n",
      "-------- After train (83)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.3284388590610703, -0.7064408887049151]]\n",
      "[2.0, -2.0]\n",
      "[-0.21596170916864488]\n",
      "-------- After train (84)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.3443573437136729, -0.7051466472477629]]\n",
      "[2.0, -2.0]\n",
      "[-0.1957908353115306]\n",
      "-------- After train (85)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.3688879567032801, -0.6856928168640216]]\n",
      "[2.0, -2.0]\n",
      "[-0.17114020007383612]\n",
      "-------- After train (86)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.39442442386609, -0.6614392104391956]]\n",
      "[2.0, -2.0]\n",
      "[-0.14557850722418764]\n",
      "-------- After train (87)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.4083882603479845, -0.6593686565969165]]\n",
      "[2.0, -2.0]\n",
      "[-0.12993856870910353]\n",
      "-------- After train (88)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.4218813000470905, -0.6573679123724168]]\n",
      "[2.0, -2.0]\n",
      "[-0.11482593748134419]\n",
      "-------- After train (89)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.433455480505984, -0.657000788367226]]\n",
      "[2.0, -2.0]\n",
      "[-0.08793761380391532]\n",
      "-------- After train (90)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.4456433585092983, -0.6565354788817547]]\n",
      "[2.0, -2.0]\n",
      "[-0.06494005771924638]\n",
      "-------- After train (91)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.4610737064364088, -0.6482251091747318]]\n",
      "[2.0, -2.0]\n",
      "[-0.04925905128238969]\n",
      "-------- After train (92)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.4726839993975362, -0.6472811422829134]]\n",
      "[2.0, -2.0]\n",
      "[-0.034547239205179534]\n",
      "-------- After train (93)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.4743069870276515, -0.6472500761907544]]\n",
      "[2.0, -2.0]\n",
      "[0.0023893663650349714]\n",
      "-------- After train (94)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.4852727065852773, -0.6465762253934288]]\n",
      "[2.0, -2.0]\n",
      "[0.01772513396556754]\n",
      "-------- After train (95)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.495659244248108, -0.6444953154301823]]\n",
      "[2.0, -2.0]\n",
      "[0.028947368364238765]\n",
      "-------- After train (96)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.5055916411077268, -0.6430225423489886]]\n",
      "[2.0, -2.0]\n",
      "[0.04007196699393975]\n",
      "-------- After train (97)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.5180546620663844, -0.6363102950087425]]\n",
      "[2.0, -2.0]\n",
      "[0.05273744367655055]\n",
      "-------- After train (98)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.5223289645893, -0.6362203141466678]]\n",
      "[2.0, -2.0]\n",
      "[0.0850234085658696]\n",
      "-------- After train (99)--------\n",
      "[[4.0, 4.0], [4.0, 4.0]]\n",
      "[[1.531288543605751, -0.6352400552991943]]\n",
      "[2.0, -2.0]\n",
      "[0.09558734488370531]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import random\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "sl_data = iris_data[:100, 0] # SetosaとVersicolor、Sepal length\n",
    "sw_data = iris_data[:100, 1] # SetosaとVersicolor、Sepal width\n",
    "\n",
    "# 平均値を0に\n",
    "sl_ave = np.average(sl_data)  # 平均値\n",
    "sl_data -= sl_ave  # 平均値を引く\n",
    "sw_ave = np.average(sw_data)\n",
    "sw_data -= sw_ave\n",
    "\n",
    "# 入力をリストに格納\n",
    "train_data = []\n",
    "for i in range(100):  # iには0から99までが入る\n",
    "    correct = iris.target[i]\n",
    "    train_data.append([sl_data[i], sw_data[i], correct])\n",
    "print(train_data)\n",
    "\n",
    "# シグモイド関数\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# ニューロン\n",
    "class Neuron:\n",
    "    def __init__(self):  # 初期設定\n",
    "        self.input_sum = 0.0\n",
    "        self.output = 0.0\n",
    "\n",
    "    def set_input(self, inp):\n",
    "        self.input_sum += inp\n",
    "\n",
    "    def get_output(self):\n",
    "        self.output = sigmoid(self.input_sum)\n",
    "        return self.output\n",
    "\n",
    "    def reset(self):\n",
    "        self.input_sum = 0\n",
    "        self.output = 0\n",
    "\n",
    "# ニューラルネットワーク\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):  # 初期設定\n",
    "        # 重み\n",
    "        self.w_im = [[4.0, 4.0], [4.0, 4.0]]  # 入力:2 ニューロン数:2\n",
    "        self.w_mo = [[1.0, -1.0]]  # 入力:2 ニューロン数:1\n",
    "\n",
    "        # バイアス\n",
    "        self.b_m = [2.0, -2.0]  # ニューロン数:2\n",
    "        self.b_o = [-0.5]  # ニューロン数:1\n",
    "\n",
    "        # 各層の宣言\n",
    "        self.input_layer = [0.0, 0.0]\n",
    "        self.middle_layer = [Neuron(), Neuron()]\n",
    "        self.output_layer = [Neuron()]\n",
    "\n",
    "    def commit(self, input_data):  # 実行\n",
    "        # 各層のリセット\n",
    "        self.input_layer[0] = input_data[0]  # 入力層は値を受け取るのみ\n",
    "        self.input_layer[1] = input_data[1]\n",
    "        self.middle_layer[0].reset()\n",
    "        self.middle_layer[1].reset()\n",
    "        self.output_layer[0].reset()\n",
    "\n",
    "        # 入力層→中間層\n",
    "        self.middle_layer[0].set_input(self.input_layer[0] * self.w_im[0][0])\n",
    "        self.middle_layer[0].set_input(self.input_layer[1] * self.w_im[0][1])\n",
    "        self.middle_layer[0].set_input(self.b_m[0])\n",
    "\n",
    "        self.middle_layer[1].set_input(self.input_layer[0] * self.w_im[1][0])\n",
    "        self.middle_layer[1].set_input(self.input_layer[1] * self.w_im[1][1])\n",
    "        self.middle_layer[1].set_input(self.b_m[1])\n",
    "\n",
    "        # 中間層→出力層\n",
    "        self.output_layer[0].set_input(self.middle_layer[0].get_output() * self.w_mo[0][0])\n",
    "        self.output_layer[0].set_input(self.middle_layer[1].get_output() * self.w_mo[0][1])\n",
    "        self.output_layer[0].set_input(self.b_o[0])\n",
    "\n",
    "        return self.output_layer[0].get_output()\n",
    "\n",
    "    def train(self, correct):\n",
    "        # 学習係数\n",
    "        k = 0.3\n",
    "\n",
    "        #  出力\n",
    "        output_o = self.output_layer[0].output\n",
    "        output_m0 = self.middle_layer[0].output\n",
    "        output_m1 = self.middle_layer[1].output\n",
    "\n",
    "        # δ\n",
    "        delta_o = (output_o - correct) * output_o * (1.0 - output_o)\n",
    "\n",
    "        # パラメータの更新\n",
    "        self.w_mo[0][0] -= k * delta_o * output_m0\n",
    "        self.w_mo[0][1] -= k * delta_o * output_m1\n",
    "        self.b_o[0] -= k * delta_o\n",
    "\n",
    "\n",
    "# ニューラルネットワークのインスタンス\n",
    "neural_network = NeuralNetwork()\n",
    "\n",
    "# 学習によるパラメータの変化\n",
    "print(\"-------- Before train --------\")\n",
    "print(neural_network.w_im)\n",
    "print(neural_network.w_mo)\n",
    "print(neural_network.b_m)\n",
    "print(neural_network.b_o)\n",
    "for i in range(100):\n",
    "    neural_network.commit(train_data[i][:2])  # 順伝播\n",
    "    neural_network.train(train_data[i][2])  # 逆伝播\n",
    "    print(\"-------- After train ({})--------\".format(i))\n",
    "    print(neural_network.w_im)\n",
    "    print(neural_network.w_mo)\n",
    "    print(neural_network.b_m)\n",
    "    print(neural_network.b_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhIYLI2A9GXp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 100)\n"
     ]
    }
   ],
   "source": [
    "# コード練習用\n",
    "print(range(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOce27aRusse1BQnq7TMl9/",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "train_output.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
